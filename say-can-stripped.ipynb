{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYKd3ZPB6s_"
      },
      "source": [
        "### Copyright 2022 Google LLC. SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLzMRizDB2l5"
      },
      "source": [
        "Copyright 2022 Google LLC. SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GrV-nN-CTpl"
      },
      "source": [
        "# SayCan on a Robot Pick and Place Tabletop Environment\n",
        "\n",
        "[SayCan](https://say-can.github.io/) is an algorithm that grounds large language models with robotic affordances for long-horizon planning. Given a set of low-level robotic skills (e.g., \"put the green block in the red bowl\") and a high-level instruction (e.g., \"stack all the blocks\"), it scores what a language model believes will help forward the high-level instruction and scores what a robotic affordance model believes is possible. Together these give a task that is useful and possible and the robot executes the command.\n",
        "\n",
        "<img src=\"https://github.com/say-can/say-can.github.io/blob/main/img/saycan.png?raw=true\" height=\"320px\">\n",
        "\n",
        "This colab runs an example of SayCan for a pick and place robot on a table top.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/say-can/say-can.github.io/main/img/open_source_tabletop.png\" height=\"320px\">\n",
        "\n",
        "Models used: [GPT-3](https://arxiv.org/abs/2005.14165) (InstructGPT), [CLIP](https://arxiv.org/abs/2103.00020) (ViT-B/32), [ViLD](https://arxiv.org/abs/2104.13921), and [CLIPort](https://cliport.github.io/) variant ([Transporter Nets](https://transporternets.github.io/))\n",
        "\n",
        "### **Quick Start on Google Collab:**\n",
        "\n",
        "**Step 1.** Register for an [OpenAI API key](https://openai.com/blog/openai-api/) to use GPT-3 (there's a free trial) and enter it below\n",
        "\n",
        "**Step 2.** Menu > Change runtime type > Hardware accelerator > \"GPU\"\n",
        "\n",
        "**Step 3.** Menu > Runtime > Run all\n",
        "\n",
        "### **Quick Start on VScode (most Mya tested)**\n",
        "**Prereqs** If you want to use a nvidia GPU, you need to have CUDA 12.X to work with this or you need to change the version of tensorflow.\n",
        "\n",
        "**Step 1.** I would recommend starting your kernel in a python venv in the current directory. \n",
        "\n",
        "**Step 2.** Menu bar > Run all\n",
        "\n",
        "\n",
        "### Troubleshooting on Ubuntu VScode\n",
        "* `OSError: Unable to download 'ffmpeg-linux64-v3.3.1'. Perhaps there is a no internet connection? If there is, please report this problem.`\n",
        "    * To fix this, run the following. NOTE: If you have an architecture different than X86 64bit replace `ffmpeg-linux-x86_64-v7.0.2` in both commands below with the name version that matches your architecture [from here](https://github.com/imageio/imageio-binaries/tree/master/ffmpeg).\n",
        "\n",
        "        ```bash\n",
        "        wget https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux-x86_64-v7.0.2\n",
        "        mv ffmpeg-linux-x86_64-v7.0.2 ~/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1\n",
        "        ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OI-l5UUxZf_I"
      },
      "outputs": [],
      "source": [
        "ENGINE = \"gpt-4o-mini\"  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2UdCCcpwbl0"
      },
      "source": [
        "## **Setup**\n",
        "This does a few things:\n",
        "- Installs dependencies: CLIP, PyTorch, etc.\n",
        "- Downloads demo videos, models, and cached LLM calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F2mFnHhPSTd_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting regex\n",
            "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting fvcore\n",
            "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
            "Collecting imageio==2.4.1\n",
            "  Using cached imageio-2.4.1-py3-none-any.whl\n",
            "Collecting imageio-ffmpeg==0.4.5\n",
            "  Using cached imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting numpy (from imageio==2.4.1)\n",
            "  Using cached numpy-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow (from imageio==2.4.1)\n",
            "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Using cached yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting pyyaml>=5.1 (from fvcore)\n",
            "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting termcolor>=1.1 (from fvcore)\n",
            "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting tabulate (from fvcore)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Using cached iopath-0.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: typing_extensions in ./.venv/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Using cached portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Using cached numpy-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: tqdm, termcolor, tabulate, regex, pyyaml, portalocker, pillow, numpy, imageio-ffmpeg, ftfy, yacs, iopath, imageio, fvcore\n",
            "Successfully installed ftfy-6.3.1 fvcore-0.1.5.post20221221 imageio-2.4.1 imageio-ffmpeg-0.4.5 iopath-0.1.10 numpy-2.2.2 pillow-11.1.0 portalocker-3.1.1 pyyaml-6.0.2 regex-2024.11.6 tabulate-0.9.0 termcolor-2.5.0 tqdm-4.67.1 yacs-0.1.8\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-_cnb1qnn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-_cnb1qnn\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: ftfy in ./.venv/lib/python3.10/site-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in ./.venv/lib/python3.10/site-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from clip==1.0) (4.67.1)\n",
            "Collecting torch (from clip==1.0)\n",
            "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision (from clip==1.0)\n",
            "  Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Collecting filelock (from torch->clip==1.0)\n",
            "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\n",
            "Collecting networkx (from torch->clip==1.0)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->clip==1.0)\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch->clip==1.0)\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->clip==1.0)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch->clip==1.0)\n",
            "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch->clip==1.0)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->clip==1.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->clip==1.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369515 sha256=130296c6440af06bca5428d696ca5c96244113f2b12cf0d8e7842c711e0d37e0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cb00qiwd/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, clip\n",
            "Successfully installed MarkupSafe-3.0.2 clip-1.0 filelock-3.17.0 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting beautifulsoup4 (from gdown)\n",
            "  Downloading beautifulsoup4-4.13.0b3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from gdown) (3.17.0)\n",
            "Collecting requests[socks] (from gdown)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from gdown) (4.67.1)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Collecting charset-normalizer<4,>=2 (from requests[socks]->gdown)\n",
            "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests[socks]->gdown)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests[socks]->gdown)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests[socks]->gdown)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Downloading beautifulsoup4-4.13.0b3-py3-none-any.whl (185 kB)\n",
            "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: urllib3, soupsieve, PySocks, idna, charset-normalizer, certifi, requests, beautifulsoup4, gdown\n",
            "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.0b3 certifi-2024.12.14 charset-normalizer-3.4.1 gdown-5.2.0 idna-3.10 requests-2.32.3 soupsieve-2.6 urllib3-2.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting pybullet\n",
            "  Using cached pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Using cached pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "Installing collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting moviepy==0.2.3.5\n",
            "  Using cached moviepy-0.2.3.5-py3-none-any.whl\n",
            "Collecting decorator<5.0,>=4.0.2 (from moviepy==0.2.3.5)\n",
            "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in ./.venv/lib/python3.10/site-packages (from moviepy==0.2.3.5) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in ./.venv/lib/python3.10/site-packages (from moviepy==0.2.3.5) (4.67.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from moviepy==0.2.3.5) (2.2.2)\n",
            "Requirement already satisfied: pillow in ./.venv/lib/python3.10/site-packages (from imageio<3.0,>=2.1.2->moviepy==0.2.3.5) (11.1.0)\n",
            "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: decorator, moviepy\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 5.1.1\n",
            "    Uninstalling decorator-5.1.1:\n",
            "      Successfully uninstalled decorator-5.1.1\n",
            "Successfully installed decorator-4.4.2 moviepy-0.2.3.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting chex==0.1.81\n",
            "  Using cached chex-0.1.81-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting optax==0.1.5\n",
            "  Using cached optax-0.1.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting absl-py>=0.9.0 (from chex==0.1.81)\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from chex==0.1.81) (4.12.2)\n",
            "Collecting dm-tree>=0.1.5 (from chex==0.1.81)\n",
            "  Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting jax>=0.4.6 (from chex==0.1.81)\n",
            "  Using cached jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib>=0.1.37 (from chex==0.1.81)\n",
            "  Using cached jaxlib-0.5.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Requirement already satisfied: numpy>=1.25.0 in ./.venv/lib/python3.10/site-packages (from chex==0.1.81) (2.2.2)\n",
            "Collecting toolz>=0.9.0 (from chex==0.1.81)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting ml_dtypes>=0.4.0 (from jax>=0.4.6->chex==0.1.81)\n",
            "  Using cached ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting opt_einsum (from jax>=0.4.6->chex==0.1.81)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting scipy>=1.11.1 (from jax>=0.4.6->chex==0.1.81)\n",
            "  Using cached scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached chex-0.1.81-py3-none-any.whl (94 kB)\n",
            "Using cached optax-0.1.5-py3-none-any.whl (164 kB)\n",
            "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "Using cached jax-0.5.0-py3-none-any.whl (2.3 MB)\n",
            "Using cached jaxlib-0.5.0-cp310-cp310-manylinux2014_x86_64.whl (102.0 MB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Installing collected packages: dm-tree, toolz, scipy, opt_einsum, ml_dtypes, absl-py, jaxlib, jax, chex, optax\n",
            "Successfully installed absl-py-2.1.0 chex-0.1.81 dm-tree-0.1.8 jax-0.5.0 jaxlib-0.5.0 ml_dtypes-0.5.1 opt_einsum-3.4.0 optax-0.1.5 scipy-1.15.1 toolz-1.0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting jax==0.4.6\n",
            "  Using cached jax-0.4.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.20 in ./.venv/lib/python3.10/site-packages (from jax==0.4.6) (2.2.2)\n",
            "Requirement already satisfied: opt_einsum in ./.venv/lib/python3.10/site-packages (from jax==0.4.6) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.5 in ./.venv/lib/python3.10/site-packages (from jax==0.4.6) (1.15.1)\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.0\n",
            "    Uninstalling jax-0.5.0:\n",
            "      Successfully uninstalled jax-0.5.0\n",
            "Successfully installed jax-0.4.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting jaxlib==0.4.6\n",
            "  Using cached jaxlib-0.4.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (963 bytes)\n",
            "Requirement already satisfied: scipy>=1.5 in ./.venv/lib/python3.10/site-packages (from jaxlib==0.4.6) (1.15.1)\n",
            "Requirement already satisfied: numpy>=1.20 in ./.venv/lib/python3.10/site-packages (from jaxlib==0.4.6) (2.2.2)\n",
            "Using cached jaxlib-0.4.6-cp310-cp310-manylinux2014_x86_64.whl (62.0 MB)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.0\n",
            "    Uninstalling jaxlib-0.5.0:\n",
            "      Successfully uninstalled jaxlib-0.5.0\n",
            "Successfully installed jaxlib-0.4.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting flax==0.5.3\n",
            "  Using cached flax-0.5.3-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.12 in ./.venv/lib/python3.10/site-packages (from flax==0.5.3) (2.2.2)\n",
            "Requirement already satisfied: jax>=0.3.2 in ./.venv/lib/python3.10/site-packages (from flax==0.5.3) (0.4.6)\n",
            "Collecting matplotlib (from flax==0.5.3)\n",
            "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting msgpack (from flax==0.5.3)\n",
            "  Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: optax in ./.venv/lib/python3.10/site-packages (from flax==0.5.3) (0.1.5)\n",
            "Collecting rich~=11.1 (from flax==0.5.3)\n",
            "  Using cached rich-11.2.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tensorstore (from flax==0.5.3)\n",
            "  Using cached tensorstore-0.1.71-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.10/site-packages (from flax==0.5.3) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in ./.venv/lib/python3.10/site-packages (from flax==0.5.3) (6.0.2)\n",
            "Requirement already satisfied: opt_einsum in ./.venv/lib/python3.10/site-packages (from jax>=0.3.2->flax==0.5.3) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.5 in ./.venv/lib/python3.10/site-packages (from jax>=0.3.2->flax==0.5.3) (1.15.1)\n",
            "Collecting colorama<0.5.0,>=0.4.0 (from rich~=11.1->flax==0.5.3)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich~=11.1->flax==0.5.3)\n",
            "  Using cached commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in ./.venv/lib/python3.10/site-packages (from rich~=11.1->flax==0.5.3) (2.19.1)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->flax==0.5.3)\n",
            "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->flax==0.5.3)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->flax==0.5.3)\n",
            "  Using cached fonttools-4.55.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (100 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->flax==0.5.3)\n",
            "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->flax==0.5.3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib->flax==0.5.3) (11.1.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->flax==0.5.3)\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib->flax==0.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in ./.venv/lib/python3.10/site-packages (from optax->flax==0.5.3) (2.1.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in ./.venv/lib/python3.10/site-packages (from optax->flax==0.5.3) (0.1.81)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in ./.venv/lib/python3.10/site-packages (from optax->flax==0.5.3) (0.4.6)\n",
            "Requirement already satisfied: ml_dtypes>=0.3.1 in ./.venv/lib/python3.10/site-packages (from tensorstore->flax==0.5.3) (0.5.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in ./.venv/lib/python3.10/site-packages (from chex>=0.1.5->optax->flax==0.5.3) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in ./.venv/lib/python3.10/site-packages (from chex>=0.1.5->optax->flax==0.5.3) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->flax==0.5.3) (1.17.0)\n",
            "Using cached flax-0.5.3-py3-none-any.whl (202 kB)\n",
            "Using cached rich-11.2.0-py3-none-any.whl (217 kB)\n",
            "Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "Using cached tensorstore-0.1.71-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.8 MB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.55.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Installing collected packages: commonmark, pyparsing, msgpack, kiwisolver, fonttools, cycler, contourpy, colorama, tensorstore, rich, matplotlib, flax\n",
            "Successfully installed colorama-0.4.6 commonmark-0.9.1 contourpy-1.3.1 cycler-0.12.1 flax-0.5.3 fonttools-4.55.7 kiwisolver-1.4.8 matplotlib-3.10.0 msgpack-1.1.0 pyparsing-3.2.1 rich-11.2.0 tensorstore-0.1.71\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting openai\n",
            "  Using cached openai-1.60.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Using cached openai-1.60.2-py3-none-any.whl (456 kB)\n",
            "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.60.2 pydantic-2.10.6 pydantic-core-2.27.2 sniffio-1.3.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting easydict\n",
            "  Using cached easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
            "Using cached easydict-1.13-py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: easydict\n",
            "Successfully installed easydict-1.13\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imageio-ffmpeg in ./.venv/lib/python3.10/site-packages (0.4.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.10/site-packages (from opencv-python) (2.2.2)\n",
            "Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting python-dotenv\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting scipy==1.12.0\n",
            "  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting numpy<1.29.0,>=1.22.4 (from scipy==1.12.0)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.2\n",
            "    Uninstalling numpy-2.2.2:\n",
            "      Successfully uninstalled numpy-2.2.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.1\n",
            "    Uninstalling scipy-1.15.1:\n",
            "      Successfully uninstalled scipy-1.15.1\n",
            "Successfully installed numpy-1.26.4 scipy-1.12.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "Successfully installed protobuf-3.20.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting tensorflow==2.18.0\n",
            "  Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (2.1.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.18.0)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow==2.18.0)\n",
            "  Using cached flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.18.0)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.18.0)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.18.0)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (59.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (4.12.2)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow==2.18.0)\n",
            "  Using cached wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.18.0)\n",
            "  Using cached grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow==2.18.0)\n",
            "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow==2.18.0)\n",
            "  Using cached keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.18.0) (1.26.4)\n",
            "Collecting h5py>=3.11.0 (from tensorflow==2.18.0)\n",
            "  Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow==2.18.0)\n",
            "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.18.0)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.18.0)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow==2.18.0) (11.2.0)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow==2.18.0)\n",
            "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow==2.18.0)\n",
            "  Using cached optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2024.12.14)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0)\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (0.4.6)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.1)\n",
            "Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "Using cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Using cached optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, tensorboard, keras, astunparse, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 optree-0.14.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/bin/bash: line 1: gsutil: command not found\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Tue Jan 28 20:27:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0  On |                  N/A |\n",
            "| N/A   53C    P4             12W /   91W |     749MiB /   8188MiB |     27%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      3095      G   /usr/lib/xorg/Xorg                            347MiB |\n",
            "|    0   N/A  N/A      3822      G   /usr/bin/gnome-shell                           67MiB |\n",
            "|    0   N/A  N/A      4505      G   ...erProcess --variations-seed-version        118MiB |\n",
            "|    0   N/A  N/A     43244      G   ...nglingPtr --variations-seed-version         40MiB |\n",
            "|    0   N/A  N/A     48332      G   ...seed-version=20250127-050148.939000        122MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "cpu\n",
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "%pip install ftfy regex tqdm fvcore imageio==2.4.1 imageio-ffmpeg==0.4.5\n",
        "%pip install git+https://github.com/openai/CLIP.git\n",
        "%pip install -U --no-cache-dir gdown --pre\n",
        "%pip install pybullet \n",
        "%pip install moviepy==0.2.3.5 # Need to downgrade to work with imageio 2.4.1\n",
        "%pip install chex==0.1.81 optax==0.1.5 # Need to downgrade to work with jax\n",
        "%pip install jax==0.4.6 # Need to downgrade to work with code\n",
        "%pip install jaxlib==0.4.6 # Need to downgrade to work with jax\n",
        "%pip install flax==0.5.3\n",
        "%pip install openai\n",
        "%pip install easydict\n",
        "%pip install imageio-ffmpeg\n",
        "%pip install opencv-python\n",
        "%pip install python-dotenv\n",
        "%pip install scipy==1.12.0\n",
        "%pip install protobuf==3.20.3 #3.20.0\n",
        "%pip install typing-extensions>=4.12.2\n",
        "%pip install tensorflow==2.18.0 #2.8.0  # Updated from 2.7.0 so that it is compatible with  CUDA 12.X\n",
        "%pip install numpy==1.26.4\n",
        "\n",
        "\n",
        "\n",
        "import collections\n",
        "import datetime\n",
        "import os\n",
        "import random\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import cv2  # Used by ViLD.\n",
        "import clip\n",
        "from easydict import EasyDict\n",
        "import flax\n",
        "from flax import linen as nn\n",
        "from flax.training import checkpoints\n",
        "from flax.metrics import tensorboard\n",
        "import imageio\n",
        "from heapq import nlargest\n",
        "import IPython\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "import numpy as np\n",
        "import openai\n",
        "import optax\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import pybullet\n",
        "import pybullet_data\n",
        "import tensorflow.compat.v1 as tf\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Load API key\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv('OPENAI_API')\n",
        "\n",
        "\n",
        "#Download PyBullet assets.\n",
        "if not os.path.exists('ur5e/ur5e.urdf'):\n",
        "  !gdown --id 1Cc_fDSBL6QiDvNT4dpfAEbhbALSVoWcc\n",
        "  !gdown --id 1yOMEm-Zp_DL3nItG9RozPeJAmeOldekX\n",
        "  !gdown --id 1GsqNLhEl9dd4Mc3BM0dX3MibOI1FVWNM\n",
        "  !unzip ur5e.zip\n",
        "  !unzip robotiq_2f_85.zip\n",
        "  !unzip bowl.zip\n",
        "\n",
        "# ViLD pretrained model weights.\n",
        "!gsutil cp -r gs://cloud-tpu-checkpoints/detection/projects/vild/colab/image_path_v2 ./\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Show useful GPU info.\n",
        "!nvidia-smi\n",
        "\n",
        "# Show if JAX is using GPU.\n",
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)\n",
        "\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment\n",
        "Define PyBullet-based environment with a UR5e and 2-finger gripper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown Global constants: pick and place objects, colors, workspace bounds\n",
        "\n",
        "PICK_TARGETS = {\n",
        "  \"blue block\": None,\n",
        "  \"red block\": None,\n",
        "  \"green block\": None,\n",
        "  \"yellow block\": None,\n",
        "}\n",
        "\n",
        "COLORS = {\n",
        "    \"blue\":   (78/255,  121/255, 167/255, 255/255),\n",
        "    \"red\":    (255/255,  87/255,  89/255, 255/255),\n",
        "    \"green\":  (89/255,  169/255,  79/255, 255/255),\n",
        "    \"yellow\": (237/255, 201/255,  72/255, 255/255),\n",
        "}\n",
        "\n",
        "PLACE_TARGETS = {\n",
        "  \"blue block\": None,\n",
        "  \"red block\": None,\n",
        "  \"green block\": None,\n",
        "  \"yellow block\": None,\n",
        "\n",
        "  \"blue bowl\": None,\n",
        "  \"red bowl\": None,\n",
        "  \"green bowl\": None,\n",
        "  \"yellow bowl\": None,\n",
        "\n",
        "  \"top left corner\":     (-0.3 + 0.05, -0.2 - 0.05, 0),\n",
        "  \"top right corner\":    (0.3 - 0.05,  -0.2 - 0.05, 0),\n",
        "  \"middle\":              (0,           -0.5,        0),\n",
        "  \"bottom left corner\":  (-0.3 + 0.05, -0.8 + 0.05, 0),\n",
        "  \"bottom right corner\": (0.3 - 0.05,  -0.8 + 0.05, 0),\n",
        "}\n",
        "\n",
        "PIXEL_SIZE = 0.00267857\n",
        "BOUNDS = np.float32([[-0.3, 0.3], [-0.8, -0.2], [0, 0.15]])  # X Y Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Iyw8Zs3Sn5"
      },
      "source": [
        "## Setup SayCan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hPk9A3lQgtcy"
      },
      "outputs": [],
      "source": [
        "#@title LLM Cache\n",
        "overwrite_cache = True\n",
        "if overwrite_cache:\n",
        "  LLM_CACHE = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u1_l-NtYRHVC"
      },
      "outputs": [],
      "source": [
        "# with open('filename.pickle', 'wb') as handle:\n",
        "#     pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# # with open('llm_cache.pickle', 'rb') as handle:\n",
        "# #     b = pickle.load(LLM_CACHE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cn53B4YsII3a"
      },
      "outputs": [],
      "source": [
        "#@title LLM Scoring\n",
        "\n",
        "def gpt3_call(engine=\"text-ada-001\", prompt=\"\", max_tokens=128, temperature=0, \n",
        "              logprobs=1, echo=False):\n",
        "  full_query = \"\"\n",
        "  for p in prompt:\n",
        "    full_query += p\n",
        "  id = tuple((engine, full_query, max_tokens, temperature, logprobs, echo))\n",
        "  if id in LLM_CACHE.keys():\n",
        "    print('cache hit, returning')\n",
        "    response = LLM_CACHE[id]\n",
        "  else:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=engine,  # Example: \"gpt-4\" or \"gpt-3.5-turbo\"\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    LLM_CACHE[id] = response\n",
        "  return response\n",
        "\n",
        "def gpt3_scoring(query, options, engine=\"text-ada-001\", limit_num_options=None, option_start=\"\\n\", verbose=False, print_tokens=False):\n",
        "  if limit_num_options:\n",
        "    options = options[:limit_num_options]\n",
        "  verbose and print(\"Scoring\", len(options), \"options\")\n",
        "  gpt3_prompt_options = [query + option for option in options]\n",
        "  response = gpt3_call(\n",
        "      engine=engine, \n",
        "      prompt=gpt3_prompt_options, \n",
        "      max_tokens=0,\n",
        "      logprobs=1, \n",
        "      temperature=0,\n",
        "      echo=True,)\n",
        "  \n",
        "  scores = {}\n",
        "  for option, choice in zip(options, response[\"choices\"]):\n",
        "    tokens = choice[\"logprobs\"][\"tokens\"]\n",
        "    token_logprobs = choice[\"logprobs\"][\"token_logprobs\"]\n",
        "\n",
        "    total_logprob = 0\n",
        "    for token, token_logprob in zip(reversed(tokens), reversed(token_logprobs)):\n",
        "      print_tokens and print(token, token_logprob)\n",
        "      if option_start is None and not token in option:\n",
        "        break\n",
        "      if token == option_start:\n",
        "        break\n",
        "      total_logprob += token_logprob\n",
        "    scores[option] = total_logprob\n",
        "\n",
        "  for i, option in enumerate(sorted(scores.items(), key=lambda x : -x[1])):\n",
        "    verbose and print(option[1], \"\\t\", option[0])\n",
        "    if i >= 10:\n",
        "      break\n",
        "\n",
        "  return scores, response\n",
        "\n",
        "def make_options(pick_targets=None, place_targets=None, options_in_api_form=True, termination_string=\"done()\"):\n",
        "  if not pick_targets:\n",
        "    pick_targets = PICK_TARGETS\n",
        "  if not place_targets:\n",
        "    place_targets = PLACE_TARGETS\n",
        "  options = []\n",
        "  for pick in pick_targets:\n",
        "    for place in place_targets:\n",
        "      if options_in_api_form:\n",
        "        option = \"robot.pick_and_place({}, {})\".format(pick, place)\n",
        "      else:\n",
        "        option = \"Pick the {} and place it on the {}.\".format(pick, place)\n",
        "      options.append(option)\n",
        "\n",
        "  options.append(termination_string)\n",
        "  print(\"Considering\", len(options), \"options\")\n",
        "  return options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Shp3CFFDzDie"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: openai\n",
            "Version: 1.60.2\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License-Expression: Apache-2.0\n",
            "Location: /home/mya/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages\n",
            "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Considering 53 options\n",
            "Scoring 5 options\n"
          ]
        },
        {
          "ename": "InvalidRequestError",
          "evalue": "Invalid type for 'messages[1].content[0]': expected an object, but got a string instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo pick the blue block and put it on the red block, I should:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m options \u001b[38;5;241m=\u001b[39m make_options(PICK_TARGETS, PLACE_TARGETS)\n\u001b[0;32m----> 4\u001b[0m scores, response \u001b[38;5;241m=\u001b[39m \u001b[43mgpt3_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mENGINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit_num_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[14], line 31\u001b[0m, in \u001b[0;36mgpt3_scoring\u001b[0;34m(query, options, engine, limit_num_options, option_start, verbose, print_tokens)\u001b[0m\n\u001b[1;32m     29\u001b[0m verbose \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScoring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(options), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m gpt3_prompt_options \u001b[38;5;241m=\u001b[39m [query \u001b[38;5;241m+\u001b[39m option \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m options]\n\u001b[0;32m---> 31\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgpt3_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt3_prompt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m option, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(options, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
            "Cell \u001b[0;32mIn[14], line 13\u001b[0m, in \u001b[0;36mgpt3_call\u001b[0;34m(engine, prompt, max_tokens, temperature, logprobs, echo)\u001b[0m\n\u001b[1;32m     11\u001b[0m   response \u001b[38;5;241m=\u001b[39m LLM_CACHE[\u001b[38;5;28mid\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Example: \"gpt-4\" or \"gpt-3.5-turbo\"\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m      \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m   LLM_CACHE[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
            "File \u001b[0;32m~/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
            "File \u001b[0;32m~/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/github/HCI/mya-plan/.venv/lib/python3.10/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: Invalid type for 'messages[1].content[0]': expected an object, but got a string instead."
          ]
        }
      ],
      "source": [
        "\n",
        "!pip show openai\n",
        "query = \"To pick the blue block and put it on the red block, I should:\\n\"\n",
        "options = make_options(PICK_TARGETS, PLACE_TARGETS)\n",
        "scores, response = gpt3_scoring(query, options, engine=ENGINE, limit_num_options=5, option_start='\\n', verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "w16kuljCGd2o"
      },
      "outputs": [],
      "source": [
        "#@title Helper Functions\n",
        "\n",
        "def build_scene_description(found_objects, block_name=\"box\", bowl_name=\"circle\"):\n",
        "  scene_description = f\"objects = {found_objects}\"\n",
        "  scene_description = scene_description.replace(block_name, \"block\")\n",
        "  scene_description = scene_description.replace(bowl_name, \"bowl\")\n",
        "  scene_description = scene_description.replace(\"'\", \"\")\n",
        "  return scene_description\n",
        "\n",
        "def step_to_nlp(step):\n",
        "  step = step.replace(\"robot.pick_and_place(\", \"\")\n",
        "  step = step.replace(\")\", \"\")\n",
        "  pick, place = step.split(\", \")\n",
        "  return \"Pick the \" + pick + \" and place it on the \" + place + \".\"\n",
        "\n",
        "def normalize_scores(scores):\n",
        "  max_score = max(scores.values())  \n",
        "  normed_scores = {key: np.clip(scores[key] / max_score, 0, 1) for key in scores}\n",
        "  return normed_scores\n",
        "\n",
        "def plot_saycan(llm_scores, vfs, combined_scores, task, correct=True, show_top=None):\n",
        "  if show_top:\n",
        "    top_options = nlargest(show_top, combined_scores, key = combined_scores.get)\n",
        "    # add a few top llm options in if not already shown\n",
        "    top_llm_options = nlargest(show_top // 2, llm_scores, key = llm_scores.get)\n",
        "    for llm_option in top_llm_options:\n",
        "      if not llm_option in top_options:\n",
        "        top_options.append(llm_option)\n",
        "    llm_scores = {option: llm_scores[option] for option in top_options}\n",
        "    vfs = {option: vfs[option] for option in top_options}\n",
        "    combined_scores = {option: combined_scores[option] for option in top_options}\n",
        "\n",
        "  sorted_keys = dict(sorted(combined_scores.items()))\n",
        "  keys = [key for key in sorted_keys]\n",
        "  positions = np.arange(len(combined_scores.items()))\n",
        "  width = 0.3\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 6))\n",
        "  ax1 = fig.add_subplot(1,1,1)\n",
        "\n",
        "  plot_llm_scores = normalize_scores({key: np.exp(llm_scores[key]) for key in sorted_keys})\n",
        "  plot_llm_scores = np.asarray([plot_llm_scores[key] for key in sorted_keys])\n",
        "  plot_affordance_scores = np.asarray([vfs[key] for key in sorted_keys])\n",
        "  plot_combined_scores = np.asarray([combined_scores[key] for key in sorted_keys])\n",
        "  \n",
        "  ax1.bar(positions, plot_combined_scores, 3 * width, alpha=0.6, color=\"#93CE8E\", label=\"combined\")\n",
        "    \n",
        "  score_colors = [\"#ea9999ff\" for score in plot_affordance_scores]\n",
        "  ax1.bar(positions + width / 2, 0 * plot_combined_scores, width, color=\"#ea9999ff\", label=\"vfs\")\n",
        "  ax1.bar(positions + width / 2, 0 * plot_combined_scores, width, color=\"#a4c2f4ff\", label=\"language\")\n",
        "  ax1.bar(positions - width / 2, np.abs(plot_affordance_scores), width, color=score_colors)\n",
        "  \n",
        "  plt.xticks(rotation=\"vertical\")\n",
        "  ax1.set_ylim(0.0, 1.0)\n",
        "\n",
        "  ax1.grid(True, which=\"both\")\n",
        "  ax1.axis(\"on\")\n",
        "\n",
        "  ax1_llm = ax1.twinx()\n",
        "  ax1_llm.bar(positions + width / 2, plot_llm_scores, width, color=\"#a4c2f4ff\", label=\"language\")\n",
        "  ax1_llm.set_ylim(0.01, 1.0)\n",
        "  plt.yscale(\"log\")\n",
        "  \n",
        "  font = {\"fontname\":\"Arial\", \"size\":\"16\", \"color\":\"k\" if correct else \"r\"}\n",
        "  plt.title(task, **font)\n",
        "  key_strings = [key.replace(\"robot.pick_and_place\", \"\").replace(\", \", \" to \").replace(\"(\", \"\").replace(\")\",\"\") for key in keys]\n",
        "  plt.xticks(positions, key_strings, **font)\n",
        "  ax1.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQ8GVvzyxP5"
      },
      "outputs": [],
      "source": [
        "#@title Affordance Scoring\n",
        "#@markdown Given this environment does not have RL-trained policies or an asscociated value function, we use affordances through an object detector.\n",
        "\n",
        "def affordance_scoring(options, found_objects, verbose=False, block_name=\"box\", bowl_name=\"circle\", termination_string=\"done()\"):\n",
        "  affordance_scores = {}\n",
        "  found_objects = [\n",
        "                   found_object.replace(block_name, \"block\").replace(bowl_name, \"bowl\") \n",
        "                   for found_object in found_objects + list(PLACE_TARGETS.keys())[-5:]]\n",
        "  verbose and print(\"found_objects\", found_objects)\n",
        "  for option in options:\n",
        "    if option == termination_string:\n",
        "      affordance_scores[option] = 0.2\n",
        "      continue\n",
        "    pick, place = option.replace(\"robot.pick_and_place(\", \"\").replace(\")\", \"\").split(\", \")\n",
        "    affordance = 0\n",
        "    found_objects_copy = found_objects.copy()\n",
        "    if pick in found_objects_copy:\n",
        "      found_objects_copy.remove(pick)\n",
        "      if place in found_objects_copy:\n",
        "        affordance = 1\n",
        "    affordance_scores[option] = affordance\n",
        "    verbose and print(affordance, '\\t', option)\n",
        "  return affordance_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xZm83muyRWR"
      },
      "outputs": [],
      "source": [
        "#@title Test\n",
        "termination_string = \"done()\"\n",
        "query = \"To pick the blue block and put it on the red block, I should:\\n\"\n",
        "\n",
        "options = make_options(PICK_TARGETS, PLACE_TARGETS, termination_string=termination_string)\n",
        "llm_scores, _ = gpt3_scoring(query, options, verbose=True, engine=ENGINE)\n",
        "\n",
        "affordance_scores = affordance_scoring(options, found_objects, block_name=\"box\", bowl_name=\"circle\", verbose=False, termination_string=termination_string)\n",
        "\n",
        "combined_scores = {option: np.exp(llm_scores[option]) * affordance_scores[option] for option in options}\n",
        "combined_scores = normalize_scores(combined_scores)\n",
        "selected_task = max(combined_scores, key=combined_scores.get)\n",
        "print(\"Selecting: \", selected_task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUQ71ADJ-HnK"
      },
      "source": [
        "# Demos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJVQIUvI77bF"
      },
      "source": [
        "## **SayCan**\n",
        "\n",
        "Here we implement SayCan with LLM scoring and robotic affordances from ViLD (in the absence of a trained value function from an RL policy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yys24Oj1796Y"
      },
      "outputs": [],
      "source": [
        "#@title Prompt\n",
        "\n",
        "termination_string = \"done()\"\n",
        "\n",
        "gpt3_context = \"\"\"\n",
        "objects = [red block, yellow block, blue block, green bowl]\n",
        "# move all the blocks to the top left corner.\n",
        "robot.pick_and_place(blue block, top left corner)\n",
        "robot.pick_and_place(red block, top left corner)\n",
        "robot.pick_and_place(yellow block, top left corner)\n",
        "done()\n",
        "\n",
        "objects = [red block, yellow block, blue block, green bowl]\n",
        "# put the yellow one the green thing.\n",
        "robot.pick_and_place(yellow block, green bowl)\n",
        "done()\n",
        "\n",
        "objects = [yellow block, blue block, red block]\n",
        "# move the light colored block to the middle.\n",
        "robot.pick_and_place(yellow block, middle)\n",
        "done()\n",
        "\n",
        "objects = [blue block, green bowl, red block, yellow bowl, green block]\n",
        "# stack the blocks.\n",
        "robot.pick_and_place(green block, blue block)\n",
        "robot.pick_and_place(red block, green block)\n",
        "done()\n",
        "\n",
        "objects = [red block, blue block, green bowl, blue bowl, yellow block, green block]\n",
        "# group the blue objects together.\n",
        "robot.pick_and_place(blue block, blue bowl)\n",
        "done()\n",
        "\n",
        "objects = [green bowl, red block, green block, red bowl, yellow bowl, yellow block]\n",
        "# sort all the blocks into their matching color bowls.\n",
        "robot.pick_and_place(green block, green bowl)\n",
        "robot.pick_and_place(red block, red bowl)\n",
        "robot.pick_and_place(yellow block, yellow bowl)\n",
        "done()\n",
        "\"\"\"\n",
        "\n",
        "use_environment_description = False\n",
        "gpt3_context_lines = gpt3_context.split(\"\\n\")\n",
        "gpt3_context_lines_keep = []\n",
        "for gpt3_context_line in gpt3_context_lines:\n",
        "  if \"objects =\" in gpt3_context_line and not use_environment_description:\n",
        "    continue\n",
        "  gpt3_context_lines_keep.append(gpt3_context_line)\n",
        "\n",
        "gpt3_context = \"\\n\".join(gpt3_context_lines_keep)\n",
        "print(gpt3_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCJckkuwFzDS"
      },
      "outputs": [],
      "source": [
        "#@title Task and Config\n",
        "only_plan = False\n",
        "\n",
        "raw_input = \"put all the blocks in different corners.\" \n",
        "config = {\"pick\":  [\"red block\", \"yellow block\", \"green block\", \"blue block\"],\n",
        "          \"place\": [\"red bowl\"]}\n",
        "\n",
        "# raw_input = \"move the block to the bowl.\"\n",
        "# config = {'pick':  ['red block'],\n",
        "#           'place': ['green bowl']}\n",
        "\n",
        "# raw_input = \"put any blocks on their matched colored bowls.\"\n",
        "# config = {'pick':  ['yellow block', 'green block', 'blue block'],\n",
        "#           'place': ['yellow bowl', 'green bowl', 'blue bowl']}\n",
        "          \n",
        "# raw_input = \"put all the blocks in the green bowl.\"\n",
        "# config = {'pick':  ['yellow block', 'green block', 'red block'],\n",
        "#           'place': ['yellow bowl', 'green bowl']}\n",
        "\n",
        "# raw_input = \"stack all the blocks.\"\n",
        "# config = {'pick':  ['yellow block', 'blue block', 'red block'],\n",
        "#           'place': ['blue bowl', 'red bowl']}\n",
        "\n",
        "# raw_input = \"make the highest block stack.\"\n",
        "# config = {'pick':  ['yellow block', 'blue block', 'red block'],\n",
        "#           'place': ['blue bowl', 'red bowl']}\n",
        "\n",
        "# raw_input = \"stack all the blocks.\"\n",
        "# config = {'pick':  ['green block', 'blue block', 'red block'],\n",
        "#           'place': ['yellow bowl', 'green bowl']}\n",
        "\n",
        "# raw_input = \"put the block in all the corners.\" \n",
        "# config = {'pick':  ['red block'],\n",
        "#           'place': ['red bowl', 'green bowl']}\n",
        "\n",
        "# raw_input = \"clockwise, move the block through all the corners.\"\n",
        "# config = {'pick':  ['red block'],\n",
        "#           'place': ['red bowl', 'green bowl', 'yellow bowl']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX18LmbIIGfz"
      },
      "outputs": [],
      "source": [
        "#@title Setup Scene\n",
        "image_path = \"./2db.png\"\n",
        "np.random.seed(2)\n",
        "if config is None:\n",
        "  pick_items = list(PICK_TARGETS.keys())\n",
        "  pick_items = np.random.choice(pick_items, size=np.random.randint(1, 5), replace=False)\n",
        "\n",
        "  place_items = list(PLACE_TARGETS.keys())[:-9]\n",
        "  place_items = np.random.choice(place_items, size=np.random.randint(1, 6 - len(pick_items)), replace=False)\n",
        "  config = {\"pick\":  pick_items,\n",
        "            \"place\": place_items}\n",
        "  print(pick_items, place_items)\n",
        "\n",
        "obs = env.reset(config)\n",
        "\n",
        "img_top = env.get_camera_image_top()\n",
        "img_top_rgb = cv2.cvtColor(img_top, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img_top)\n",
        "\n",
        "imageio.imsave(image_path, img_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4Yh-PqZ-03n"
      },
      "outputs": [],
      "source": [
        "#@title Runner\n",
        "plot_on = True\n",
        "max_tasks = 5\n",
        "\n",
        "options = make_options(PICK_TARGETS, PLACE_TARGETS, termination_string=termination_string)\n",
        "found_objects = vild(image_path, category_name_string, vild_params, plot_on=False)\n",
        "scene_description = build_scene_description(found_objects)\n",
        "env_description = scene_description\n",
        "\n",
        "print(scene_description)\n",
        "\n",
        "gpt3_prompt = gpt3_context\n",
        "if use_environment_description:\n",
        "  gpt3_prompt += \"\\n\" + env_description\n",
        "gpt3_prompt += \"\\n# \" + raw_input + \"\\n\"\n",
        "\n",
        "all_llm_scores = []\n",
        "all_affordance_scores = []\n",
        "all_combined_scores = []\n",
        "affordance_scores = affordance_scoring(options, found_objects, block_name=\"box\", bowl_name=\"circle\", verbose=False)\n",
        "num_tasks = 0\n",
        "selected_task = \"\"\n",
        "steps_text = []\n",
        "while not selected_task == termination_string:\n",
        "  num_tasks += 1\n",
        "  if num_tasks > max_tasks:\n",
        "    break\n",
        "\n",
        "  llm_scores, _ = gpt3_scoring(gpt3_prompt, options, verbose=True, engine=ENGINE, print_tokens=False)\n",
        "  combined_scores = {option: np.exp(llm_scores[option]) * affordance_scores[option] for option in options}\n",
        "  combined_scores = normalize_scores(combined_scores)\n",
        "  selected_task = max(combined_scores, key=combined_scores.get)\n",
        "  steps_text.append(selected_task)\n",
        "  print(num_tasks, \"Selecting: \", selected_task)\n",
        "  gpt3_prompt += selected_task + \"\\n\"\n",
        "\n",
        "  all_llm_scores.append(llm_scores)\n",
        "  all_affordance_scores.append(affordance_scores)\n",
        "  all_combined_scores.append(combined_scores)\n",
        "\n",
        "if plot_on:\n",
        "  for llm_scores, affordance_scores, combined_scores, step in zip(\n",
        "      all_llm_scores, all_affordance_scores, all_combined_scores, steps_text):\n",
        "    plot_saycan(llm_scores, affordance_scores, combined_scores, step, show_top=10)\n",
        "\n",
        "print('**** Solution ****')\n",
        "print(env_description)\n",
        "print('# ' + raw_input)\n",
        "for i, step in enumerate(steps_text):\n",
        "  if step == '' or step == termination_string:\n",
        "    break\n",
        "  print('Step ' + str(i) + ': ' + step)\n",
        "  nlp_step = step_to_nlp(step)\n",
        "\n",
        "if not only_plan:\n",
        "  print('Initial state:')\n",
        "  plt.imshow(env.get_camera_image())\n",
        "\n",
        "  for i, step in enumerate(steps_text):\n",
        "    if step == '' or step == termination_string:\n",
        "      break\n",
        "    nlp_step = step_to_nlp(step)\n",
        "    print('GPT-3 says next step:', nlp_step)\n",
        "\n",
        "    obs = run_cliport(obs, nlp_step)\n",
        "\n",
        "  # Show camera image after task.\n",
        "  print('Final state:')\n",
        "  plt.imshow(env.get_camera_image())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWQwjuiDi1nC"
      },
      "source": [
        "## Socratic Model: VILD, GPT3, CLIPort\n",
        "\n",
        "This implements a version of LLM planning shown in [Socratic Models](https://socraticmodels.github.io/), without the grounding, but with a scene description. For this relatively simple environment with clear robotic affordances, the scene description is generally sufficient. This mirrors the implementation attached to the paper [here](https://github.com/google-research/google-research/tree/master/socraticmodels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trXP07uypWL8"
      },
      "outputs": [],
      "source": [
        "#@title Prompt\n",
        "\n",
        "gpt3_context = \"\"\"\n",
        "objects = [red block, yellow block, blue block, green bowl]\n",
        "# move all the blocks to the top left corner.\n",
        "robot.pick_and_place(blue block, top left corner)\n",
        "robot.pick_and_place(red block, top left corner)\n",
        "robot.pick_and_place(yellow block, top left corner)\n",
        "done()\n",
        "\n",
        "objects = [red block, yellow block, blue block, green bowl]\n",
        "# put the yellow one the green thing.\n",
        "robot.pick_and_place(yellow block, green bowl)\n",
        "done()\n",
        "\n",
        "objects = [yellow block, blue block, red block]\n",
        "# move the light colored block to the middle.\n",
        "robot.pick_and_place(yellow block, middle)\n",
        "done()\n",
        "\n",
        "objects = [blue block, green bowl, red block, yellow bowl, green block]\n",
        "# stack the blocks.\n",
        "robot.pick_and_place(green block, blue block)\n",
        "robot.pick_and_place(red block, green block)\n",
        "done()\n",
        "\n",
        "objects = [red block, blue block, green bowl, blue bowl, yellow block, green block]\n",
        "# group the blue objects together.\n",
        "robot.pick_and_place(blue block, blue bowl)\n",
        "done()\n",
        "\n",
        "objects = [green bowl, red block, green block, red bowl, yellow bowl, yellow block]\n",
        "# sort all the blocks into their matching color bowls.\n",
        "robot.pick_and_place(green block, green bowl)\n",
        "robot.pick_and_place(red block, red bowl)\n",
        "robot.pick_and_place(yellow block, yellow bowl)\n",
        "done()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPx--Ea7IZ69"
      },
      "outputs": [],
      "source": [
        "#@title Queries and Configs\n",
        "\n",
        "only_plan = False\n",
        "\n",
        "raw_input = \"put all the blocks in different corners.\" \n",
        "config = {'pick':  ['red block', 'yellow block', 'green block', 'blue block'],\n",
        "          'place': ['red bowl']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6TSgRItpPC4"
      },
      "outputs": [],
      "source": [
        "#@title Runner\n",
        "\n",
        "env_description = ''\n",
        "image_path = './2db.png'\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "if config is None:\n",
        "  pick_items = list(PICK_TARGETS.keys())\n",
        "  pick_items = np.random.choice(pick_items, size=np.random.randint(1, 5), replace=False)\n",
        "\n",
        "  place_items = list(PLACE_TARGETS.keys())[:-9]\n",
        "  place_items = np.random.choice(place_items, size=np.random.randint(1, 6 - len(pick_items)), replace=False)\n",
        "  config = {'pick':  pick_items,\n",
        "            'place': place_items}\n",
        "  print(pick_items, place_items)\n",
        "obs = env.reset(config)\n",
        "\n",
        "img_top = env.get_camera_image_top()\n",
        "img_top_rgb = cv2.cvtColor(img_top, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img_top_rgb)\n",
        "\n",
        "imageio.imsave(image_path, img_top)\n",
        "\n",
        "found_objects = vild(image_path, category_name_string, vild_params, plot_on=False)\n",
        "scene_description = build_scene_description(found_objects)\n",
        "print(scene_description)\n",
        "\n",
        "env_description = scene_description\n",
        "\n",
        "gpt3_prompt = gpt3_context\n",
        "gpt3_prompt += \"\\n\" + env_description + \"\\n\"\n",
        "gpt3_prompt += \"# \" + raw_input\n",
        "response = gpt3_call(engine=ENGINE, prompt=gpt3_prompt, max_tokens=128, temperature=0)\n",
        "steps_text = [text.strip().strip() for text in response[\"choices\"][0][\"text\"].strip().split(\"#\")[0].split(\"\\n\")][:-1]\n",
        "print('**** Solution ****')\n",
        "print(env_description)\n",
        "print('# ' + raw_input)\n",
        "for i, step in enumerate(steps_text):\n",
        "  if step == '' or step == termination_string:\n",
        "    break\n",
        "  print('Step ' + str(i) + ': ' + step)\n",
        "  nlp_step = step_to_nlp(step)\n",
        "\n",
        "if not only_plan:\n",
        "  print('Initial state:')\n",
        "  plt.imshow(env.get_camera_image())\n",
        "\n",
        "  for i, step in enumerate(steps_text):\n",
        "    if step == '' or step == termination_string:\n",
        "      break\n",
        "    nlp_step = step_to_nlp(step)\n",
        "    print('GPT-3 says next step:', nlp_step)\n",
        "\n",
        "    obs = run_cliport(obs, nlp_step)\n",
        "\n",
        "  # Show camera image after task.\n",
        "  print('Final state:')\n",
        "  plt.imshow(env.get_camera_image())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SayCan_Robot_Pick_Place.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
